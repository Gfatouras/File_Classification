{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1eb6cf8e-ea8d-447f-b051-7610d06efc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7634624e-9831-4e03-9209-d5695f794e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>article</th>\n",
       "      <th>audited financial statements</th>\n",
       "      <th>aum</th>\n",
       "      <th>capital committed invested</th>\n",
       "      <th>cco notes</th>\n",
       "      <th>compliance other</th>\n",
       "      <th>compliance business continuity manual</th>\n",
       "      <th>conference call</th>\n",
       "      <th>conference meeting notes</th>\n",
       "      <th>...</th>\n",
       "      <th>reference notes</th>\n",
       "      <th>risk management policy</th>\n",
       "      <th>risk report</th>\n",
       "      <th>service provider information</th>\n",
       "      <th>side letter</th>\n",
       "      <th>tax information</th>\n",
       "      <th>term sheet</th>\n",
       "      <th>unaudited financial statements</th>\n",
       "      <th>valuation policy</th>\n",
       "      <th>wire instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quarterly manager blurb - 2024.xlsx</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>verition commentary &amp; risk report_september 20...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saba capital carry neutral tail fund - risk re...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lcm fund risk report september 2024.pdf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbey futures fund - monthly report_30 sep 202...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120817</th>\n",
       "      <td>high tech high capital campaign plan.doc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120818</th>\n",
       "      <td>diane l.myer foundation investment policy.doc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120819</th>\n",
       "      <td>dlj wire letter.doc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120820</th>\n",
       "      <td>initial donation mar 24 00.doc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120821</th>\n",
       "      <td>initial donation mar 14 00.doc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120822 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  article  \\\n",
       "0                     quarterly manager blurb - 2024.xlsx      0.0   \n",
       "1       verition commentary & risk report_september 20...      0.0   \n",
       "2       saba capital carry neutral tail fund - risk re...      0.0   \n",
       "3                 lcm fund risk report september 2024.pdf      0.0   \n",
       "4       abbey futures fund - monthly report_30 sep 202...      0.0   \n",
       "...                                                   ...      ...   \n",
       "120817           high tech high capital campaign plan.doc      0.0   \n",
       "120818      diane l.myer foundation investment policy.doc      0.0   \n",
       "120819                                dlj wire letter.doc      0.0   \n",
       "120820                     initial donation mar 24 00.doc      0.0   \n",
       "120821                     initial donation mar 14 00.doc      0.0   \n",
       "\n",
       "        audited financial statements  aum  capital committed invested  \\\n",
       "0                                0.0  0.0                         0.0   \n",
       "1                                0.0  0.0                         0.0   \n",
       "2                                0.0  0.0                         1.0   \n",
       "3                                0.0  0.0                         0.0   \n",
       "4                                0.0  0.0                         0.0   \n",
       "...                              ...  ...                         ...   \n",
       "120817                           0.0  0.0                         1.0   \n",
       "120818                           0.0  0.0                         0.0   \n",
       "120819                           0.0  0.0                         0.0   \n",
       "120820                           0.0  0.0                         0.0   \n",
       "120821                           0.0  0.0                         0.0   \n",
       "\n",
       "        cco notes  compliance other  compliance business continuity manual  \\\n",
       "0             0.0               0.0                                    0.0   \n",
       "1             0.0               0.0                                    0.0   \n",
       "2             0.0               0.0                                    0.0   \n",
       "3             0.0               0.0                                    0.0   \n",
       "4             0.0               0.0                                    0.0   \n",
       "...           ...               ...                                    ...   \n",
       "120817        0.0               0.0                                    0.0   \n",
       "120818        0.0               0.0                                    0.0   \n",
       "120819        0.0               0.0                                    0.0   \n",
       "120820        0.0               0.0                                    0.0   \n",
       "120821        0.0               0.0                                    0.0   \n",
       "\n",
       "        conference call  conference meeting notes  ...  reference notes  \\\n",
       "0                   0.0                       0.0  ...              0.0   \n",
       "1                   0.0                       0.0  ...              0.0   \n",
       "2                   0.0                       0.0  ...              0.0   \n",
       "3                   0.0                       0.0  ...              0.0   \n",
       "4                   0.0                       0.0  ...              0.0   \n",
       "...                 ...                       ...  ...              ...   \n",
       "120817              0.0                       0.0  ...              0.0   \n",
       "120818              0.0                       0.0  ...              0.0   \n",
       "120819              0.0                       0.0  ...              0.0   \n",
       "120820              0.0                       0.0  ...              0.0   \n",
       "120821              0.0                       0.0  ...              0.0   \n",
       "\n",
       "        risk management policy  risk report  service provider information  \\\n",
       "0                          0.0          0.0                           0.0   \n",
       "1                          1.0          1.0                           0.0   \n",
       "2                          1.0          2.0                           0.0   \n",
       "3                          1.0          2.0                           0.0   \n",
       "4                          0.0          0.0                           0.0   \n",
       "...                        ...          ...                           ...   \n",
       "120817                     0.0          0.0                           0.0   \n",
       "120818                     0.0          0.0                           0.0   \n",
       "120819                     0.0          0.0                           0.0   \n",
       "120820                     0.0          0.0                           0.0   \n",
       "120821                     0.0          0.0                           0.0   \n",
       "\n",
       "        side letter  tax information  term sheet  \\\n",
       "0               0.0              0.0         0.0   \n",
       "1               0.0              0.0         0.0   \n",
       "2               0.0              0.0         0.0   \n",
       "3               0.0              0.0         0.0   \n",
       "4               0.0              0.0         0.0   \n",
       "...             ...              ...         ...   \n",
       "120817          0.0              0.0         0.0   \n",
       "120818          0.0              0.0         0.0   \n",
       "120819          0.0              0.0         0.0   \n",
       "120820          0.0              0.0         0.0   \n",
       "120821          0.0              0.0         0.0   \n",
       "\n",
       "        unaudited financial statements  valuation policy  wire instructions  \n",
       "0                                  0.0               0.0                0.0  \n",
       "1                                  0.0               0.0                0.0  \n",
       "2                                  0.0               0.0                0.0  \n",
       "3                                  0.0               0.0                0.0  \n",
       "4                                  0.0               0.0                0.0  \n",
       "...                                ...               ...                ...  \n",
       "120817                             0.0               0.0                0.0  \n",
       "120818                             0.0               0.0                0.0  \n",
       "120819                             0.0               0.0                1.0  \n",
       "120820                             0.0               0.0                0.0  \n",
       "120821                             0.0               0.0                0.0  \n",
       "\n",
       "[120822 rows x 52 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"result_df.csv\")\n",
    "#df = df.sample(120000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ddef8284-8ef7-4cdd-b9cc-f9febbe5f79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregory.fatouras\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.41%\n",
      "Hamming Loss: 0.002539\n",
      "File: picton mahoney - firm financial statements 2016.pdf\n",
      "Predicted category based on keyword: financial report\n",
      "\n",
      "\n",
      "File: flagship historical risk data 04302022.xlsx\n",
      "Predicted categories based on model: risk management policy, risk report\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom tokenizer function\n",
    "def custom_tokenizer(file_name):\n",
    "    # Split date-like patterns (e.g., '2018-19' -> '2018 19')\n",
    "    file_name = re.sub(r'(\\d{4})-(\\d{2})', r'\\1 \\2', file_name)\n",
    "    \n",
    "    # Split camelCase words (e.g., 'MTHSandNVHS' -> 'MTH Sand NVHS')\n",
    "    file_name = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', file_name)\n",
    "    \n",
    "    # Convert file name to lower case and split by non-alphanumeric characters\n",
    "    tokens = re.findall(r'\\b\\w+\\b', file_name.lower())  # \\w matches letters, numbers, and underscores\n",
    "    return tokens\n",
    "\n",
    "# Example: Splitting the data\n",
    "X = df['name']  # File names\n",
    "y = (df.drop(columns=['name']) > 0).astype(int)  # Multi-labels, assuming >0 means presence of a category\n",
    "\n",
    "# Step 1: Apply TF-IDF Vectorization with custom tokenizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', tokenizer=custom_tokenizer)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 2: Train the model\n",
    "model = OneVsRestClassifier(LogisticRegression(max_iter=10000, random_state=42))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 4: Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "\n",
    "# Print Accuracy and Hamming Loss\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Hamming Loss: {hamming:.6f}\")\n",
    "\n",
    "# Step 5: Define keyword-based checks for additional classification\n",
    "def apply_keyword_rules(file_name):\n",
    "    \"\"\"Keyword-based rule to detect presentation type files.\"\"\"\n",
    "    keywords = {\n",
    "        'presentation': 'presentation',\n",
    "        'report': 'report',\n",
    "        'proposal': 'proposal',\n",
    "        'meeting': 'meeting',\n",
    "        'financial': 'financial report'\n",
    "    }\n",
    "    \n",
    "    file_name = file_name.lower()  # Case-insensitive\n",
    "    for keyword, category in keywords.items():\n",
    "        if keyword in file_name:\n",
    "            return category  # Return the category based on the keyword match\n",
    "    return None  # If no match, return None\n",
    "\n",
    "# Example to predict for new files\n",
    "new_files = [\"picton mahoney - firm financial statements 2016.pdf\", \"flagship historical risk data 04302022.xlsx\"]\n",
    "for file in new_files:\n",
    "    predicted_category = apply_keyword_rules(file)\n",
    "    \n",
    "    if predicted_category:\n",
    "        print(f\"File: {file}\")\n",
    "        print(f\"Predicted category based on keyword: {predicted_category}\")\n",
    "    else:\n",
    "        # If no match from keyword, proceed with TF-IDF + model predictions\n",
    "        X_new = vectorizer.transform([file])  # Transform the new file name\n",
    "        y_pred_new = model.predict(X_new)\n",
    "        \n",
    "        # Extract the predicted categories based on the model output\n",
    "        predicted_categories = df.columns[1:][y_pred_new[0] == 1].tolist()  # Assuming columns[1:] are categories\n",
    "        \n",
    "        print(f\"File: {file}\")\n",
    "        if predicted_categories:\n",
    "            print(f\"Predicted categories based on model: {', '.join(predicted_categories)}\")\n",
    "        else:\n",
    "            print(\"Predicted categories: None\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3336d6-b20b-4a1f-916f-6a87c36b5a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregory.fatouras\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\gregory.fatouras\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m327/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14s\u001b[0m 289ms/step - accuracy: 0.6517 - loss: 0.6862"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Custom tokenizer function\n",
    "def custom_tokenizer(file_name):\n",
    "    file_name = re.sub(r'(\\d{4})-(\\d{2})', r'\\1 \\2', file_name)  # Split date-like patterns\n",
    "    file_name = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', file_name)  # Split camelCase words\n",
    "    tokens = re.findall(r'\\b\\w+\\b', file_name.lower())  # Tokenize by non-alphanumeric characters\n",
    "    return tokens\n",
    "\n",
    "\n",
    "X = df['name']  # File names\n",
    "\n",
    "# Multi-label binarizer to transform labels into a binary matrix (1 if a file has a category, 0 if not)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df.drop(columns=['name']).values)\n",
    "\n",
    "# Step 1: Apply TF-IDF Vectorization with custom tokenizer\n",
    "vectorizer = TfidfVectorizer(max_features=50000, stop_words='english', tokenizer=custom_tokenizer)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 2: Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Build the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))  # Input layer with ReLU activation\n",
    "model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
    "model.add(Dense(256, activation='relu'))  # Hidden layer 1\n",
    "model.add(Dropout(0.5))  # Dropout layer\n",
    "model.add(Dense(128, activation='relu'))  # Hidden layer 2\n",
    "model.add(Dropout(0.5))  # Dropout layer\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))  # Sigmoid for multi-label classification\n",
    "\n",
    "# Step 4: Set a custom learning rate and compile the model\n",
    "custom_learning_rate = 0.00001  # Define your custom learning rate here\n",
    "optimizer = Adam(learning_rate=custom_learning_rate)  # Pass the custom learning rate to Adam optimizer\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 6: Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 7: Predict for new files\n",
    "new_files = [\"picton mahoney - firm financial statements 2016.pdf\", \"flagship historical risk data 04302022.xlsx\"]\n",
    "new_files_tfidf = vectorizer.transform(new_files)\n",
    "\n",
    "predictions = model.predict(new_files_tfidf)\n",
    "\n",
    "# Convert predictions to categories\n",
    "predicted_categories = mlb.inverse_transform(predictions > 0.5)  # Threshold predictions at 0.5 to get categories\n",
    "\n",
    "for file, categories in zip(new_files, predicted_categories):\n",
    "    print(f\"File: {file}\")\n",
    "    if categories:\n",
    "        print(f\"Predicted categories: {', '.join(categories)}\")\n",
    "    else:\n",
    "        print(\"Predicted categories: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7f780-3a86-4cba-afce-05e5fe5dc470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
